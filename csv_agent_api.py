"""
API-–≤–µ—Ä—Å–∏—è CSV Analysis Agent –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏
Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–∞—Å–∏–≤—ã–º –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ CSV
"""

import os
import io
import json
import traceback
import gc
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import contextlib
import base64
from datetime import datetime

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from openai import OpenAI


# –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å - Claude Sonnet 4.5
MODEL_ID = "anthropic/claude-sonnet-4.5"
MODEL_NAME = "Claude Sonnet 4.5"


class CSVAnalysisAgentAPI:
    """
    API-–≤–µ—Ä—Å–∏—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è CSV —Ñ–∞–π–ª–æ–≤ (Julius.ai style)
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ CSV
    """

    def __init__(self, api_key: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞

        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter
        """
        self.api_key = api_key

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )

        self.model = MODEL_ID
        self.model_name = MODEL_NAME

        self.current_df = None
        self.original_df = None  # –•—Ä–∞–Ω–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        self.current_filename = None
        self.max_retries = 3

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –¥–∞–Ω–Ω—ã—Ö
        self.data_metadata = {
            "has_unnamed_columns": False,
            "first_row_is_header": False,
            "columns_cleaned": False,
            "rows_removed": 0,
            "cols_removed": 0,
            "was_edited": False
        }

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        sns.set_style("whitegrid")
        plt.rcParams['figure.figsize'] = (10, 6)
        plt.rcParams['figure.dpi'] = 100

    def _is_first_row_header(self, df: pd.DataFrame) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º

        –ö—Ä–∏—Ç–µ—Ä–∏–∏:
        1. –¢–µ–∫—É—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∏–ø–∞ "Unnamed: 0", "Unnamed: 1"...
        2. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
        3. –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–æ–≤—ã–µ/—Å–º–µ—à–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–∞–Ω–Ω—ã–µ)
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ú–Ω–æ–≥–æ Unnamed –∫–æ–ª–æ–Ω–æ–∫?
        unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
        if unnamed_count < len(df.columns) * 0.3:  # –ú–µ–Ω—å—à–µ 30% unnamed
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ç–µ–∫—Å—Ç?
        if len(df) < 2:
            return False

        first_row = df.iloc[0]
        second_row = df.iloc[1]

        # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        text_count_row1 = sum(1 for val in first_row if isinstance(val, str) and not str(val).replace('.', '').replace('-', '').isdigit())

        # –°—á–∏—Ç–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–µ
        numeric_count_row2 = sum(1 for val in second_row if pd.notna(val) and (isinstance(val, (int, float)) or str(val).replace('.', '').replace('-', '').isdigit()))

        # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç, –∞ –≤—Ç–æ—Ä–∞—è - —á–∏—Å–ª–∞
        return text_count_row1 > len(first_row) * 0.5 and numeric_count_row2 > len(second_row) * 0.3

    def _detect_separator(self, file_bytes: bytes) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV —Ñ–∞–π–ª–∞
        """
        try:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            sample = file_bytes[:8192].decode('utf-8', errors='ignore')
            lines = sample.split('\n')[:5]
            
            separators = [',', ';', '\t', '|']
            sep_counts = {}
            
            for sep in separators:
                counts = [line.count(sep) for line in lines if line.strip()]
                if counts:
                    # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤–æ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                    if len(set(counts)) == 1 and counts[0] > 0:
                        sep_counts[sep] = counts[0]
                    elif counts:
                        sep_counts[sep] = max(counts)
            
            if sep_counts:
                return max(sep_counts, key=sep_counts.get)
            return ','
        except:
            return ','

    def _detect_encoding(self, file_bytes: bytes) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞
        """
        encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'latin-1', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                file_bytes.decode(encoding)
                return encoding
            except:
                continue
        
        return 'utf-8'

    def smart_load_csv(self, file_bytes: bytes, filename: str = "data.csv") -> Dict[str, Any]:
        """
        –£–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ Julius.ai - —Å–Ω–∞—á–∞–ª–∞ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø–æ—Ç–æ–º –æ—á–∏—â–∞–µ—Ç

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –æ—á–∏—Å—Ç–∫–µ
        """
        load_info = {
            "filename": filename,
            "steps": [],
            "warnings": [],
            "original_shape": None,
            "final_shape": None,
            "success": True
        }

        self.current_filename = filename

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏ –∫–æ–¥–∏—Ä–æ–≤–∫—É
            sep = self._detect_separator(file_bytes)
            encoding = self._detect_encoding(file_bytes)
            
            load_info["steps"].append(f"üîç –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}', –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")

            # –®–ê–ì 1: –ó–∞–≥—Ä—É–∂–∞–µ–º "–∫–∞–∫ –µ—Å—Ç—å"
            df_raw = pd.read_csv(io.BytesIO(file_bytes), sep=sep, encoding=encoding, on_bad_lines='skip')
            self.original_df = df_raw.copy()
            load_info["original_shape"] = df_raw.shape
            load_info["steps"].append(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df_raw.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df_raw.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º "Unnamed" –∫–æ–ª–æ–Ω–∫–∏
            unnamed_cols = [col for col in df_raw.columns if 'Unnamed' in str(col)]
            if unnamed_cols:
                self.data_metadata["has_unnamed_columns"] = True
                load_info["warnings"].append(
                    f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(unnamed_cols)} –∫–æ–ª–æ–Ω–æ–∫ —Ç–∏–ø–∞ 'Unnamed'. "
                    f"–í–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏."
                )
                load_info["steps"].append(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(unnamed_cols)} –±–µ–∑—ã–º—è–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É - –º–æ–∂–µ—Ç —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏?
            if self._is_first_row_header(df_raw):
                self.data_metadata["first_row_is_header"] = True
                load_info["steps"].append("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

                # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                new_columns = df_raw.iloc[0].tolist()
                df_raw.columns = new_columns
                df_raw = df_raw.iloc[1:].reset_index(drop=True)

                load_info["steps"].append("‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏")

            # –®–ê–ì 4: –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤
            original_cols = list(df_raw.columns)
            df_raw.columns = df_raw.columns.astype(str).str.strip()
            cleaned_cols = list(df_raw.columns)

            if original_cols != cleaned_cols:
                self.data_metadata["columns_cleaned"] = True
                load_info["steps"].append("üßπ –û—á–∏—â–µ–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤")

            # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            rows_before = len(df_raw)
            df_raw = df_raw.dropna(how='all')
            rows_after = len(df_raw)
            rows_removed = rows_before - rows_after

            if rows_removed > 0:
                self.data_metadata["rows_removed"] = rows_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")

            # –®–ê–ì 6: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            cols_before = len(df_raw.columns)
            df_raw = df_raw.dropna(axis=1, how='all')
            cols_after = len(df_raw.columns)
            cols_removed = cols_before - cols_after

            if cols_removed > 0:
                self.data_metadata["cols_removed"] = cols_removed
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {cols_removed} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

            # –®–ê–ì 7: –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–æ–ª—å–∫–æ NaN/–ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            # –∏ –∫–æ–ª–æ–Ω–∫–∏ —Ç–∏–ø–∞ "Unnamed" –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ
            cols_to_drop = []
            for col in df_raw.columns:
                if 'Unnamed' in str(col):
                    if df_raw[col].isna().all() or (df_raw[col].astype(str).str.strip() == '').all():
                        cols_to_drop.append(col)
            
            if cols_to_drop:
                df_raw = df_raw.drop(columns=cols_to_drop)
                load_info["steps"].append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(cols_to_drop)} –ø—É—Å—Ç—ã—Ö Unnamed –∫–æ–ª–æ–Ω–æ–∫")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.current_df = df_raw.reset_index(drop=True)

            load_info["final_shape"] = self.current_df.shape
            load_info["steps"].append(
                f"‚úÖ –ò—Ç–æ–≥–æ: {self.current_df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {self.current_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫"
            )

            return load_info

        except Exception as e:
            load_info["success"] = False
            load_info["error"] = str(e)
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV —Ñ–∞–π–ª–∞ '{filename}': {str(e)}")

    def load_csv_from_bytes(self, file_bytes: bytes, filename: str = "data.csv") -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –∏–∑ –±–∞–π—Ç–æ–≤ (—Å —É–º–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π)

        Args:
            file_bytes: –ë–∞–π—Ç—ã CSV —Ñ–∞–π–ª–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞

        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        self.smart_load_csv(file_bytes, filename)
        return self.current_df

    def load_csv_from_file(self, file_path: str) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV –∏–∑ –ø—É—Ç–∏

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            DataFrame
        """
        with open(file_path, 'rb') as f:
            file_bytes = f.read()
        return self.load_csv_from_bytes(file_bytes, os.path.basename(file_path))

    def analyze_csv_schema(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã CSV —Ñ–∞–π–ª–∞

        Args:
            df: DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ö–µ–º–µ
        """
        schema = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": {"rows": int(df.shape[0]), "columns": int(df.shape[1])},
            "missing_values": {col: int(count) for col, count in df.isnull().sum().items()},
            "sample_data": df.head(5).to_dict(orient='records'),
            "summary_stats": {},
            "metadata": self.data_metadata
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats_df = df[numeric_cols].describe()
            schema["summary_stats"] = {
                col: {stat: float(val) for stat, val in stats_df[col].items()}
                for col in numeric_cols
            }

        return schema

    def df_to_csv_base64(self, df: pd.DataFrame = None) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –≤ base64 CSV

        Args:
            df: DataFrame –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é current_df)

        Returns:
            Base64 —Å—Ç—Ä–æ–∫–∞ CSV —Ñ–∞–π–ª–∞
        """
        if df is None:
            df = self.current_df
        
        if df is None:
            return None
        
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        csv_bytes = csv_buffer.getvalue().encode('utf-8-sig')
        return base64.b64encode(csv_bytes).decode('utf-8')

    def execute_python_code(self, code: str, df: pd.DataFrame) -> Tuple[bool, Any, str, List[str], Optional[pd.DataFrame]]:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Python –∫–æ–¥–∞ —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ base64
        –∏ –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ DataFrame

        Args:
            code: Python –∫–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            df: DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –≤—ã–≤–æ–¥/–æ—à–∏–±–∫–∞, —Å–ø–∏—Å–æ–∫ base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π DataFrame)
        """
        local_vars = {
            'df': df.copy(),
            'pd': pd,
            'np': np,
            'plt': plt,
            'sns': sns,
            'result': None,
            'modified_df': None  # –î–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–≥–æ DataFrame
        }

        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()
        plot_base64_list = []
        modified_df = None

        try:
            with contextlib.redirect_stdout(stdout_capture), \
                 contextlib.redirect_stderr(stderr_capture):

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
                exec(code, local_vars)

                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result = local_vars.get('result', None)
                output = stdout_capture.getvalue()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –∏–∑–º–µ–Ω—ë–Ω DataFrame
                modified_df = local_vars.get('modified_df', None)
                
                # –ï—Å–ª–∏ modified_df –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —è–≤–Ω–æ, –Ω–æ df –±—ã–ª –∏–∑–º–µ–Ω—ë–Ω
                if modified_df is None and 'df' in local_vars:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ df
                    current_df = local_vars['df']
                    if not current_df.equals(df):
                        modified_df = current_df

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON-serializable —Ñ–æ—Ä–º–∞—Ç
                if isinstance(result, (np.integer, np.floating)):
                    result = float(result)
                elif isinstance(result, np.ndarray):
                    result = result.tolist()
                elif isinstance(result, pd.DataFrame) or isinstance(result, pd.Series):
                    result = str(result)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –≤ base64
                if plt.get_fignums():
                    for fig_num in plt.get_fignums():
                        fig = plt.figure(fig_num)

                        buffer = io.BytesIO()
                        fig.savefig(buffer, format='png', bbox_inches='tight', dpi=150)
                        buffer.seek(0)

                        img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
                        plot_base64_list.append(f"data:image/png;base64,{img_base64}")

                        buffer.close()

                    plt.close('all')

                return True, result, output, plot_base64_list, modified_df

        except Exception as e:
            error_msg = f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"
            return False, None, error_msg, [], None
        finally:
            plt.close('all')
            plt.clf()
            local_vars.clear()

    def auto_clean_data(self) -> Dict[str, Any]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª, –Ω–æ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—á–∏—Å—Ç–∫–∏ —Å –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º CSV
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
            }
        
        df = self.current_df.copy()
        cleaning_steps = []
        original_shape = df.shape
        
        # –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        rows_to_skip = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫
        for i in range(min(5, len(df))):
            row = df.iloc[i]
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –º—É—Å–æ—Ä
            nan_count = row.isna().sum()
            if nan_count > len(row) * 0.8:  # –ë–æ–ª–µ–µ 80% –ø—É—Å—Ç—ã—Ö
                rows_to_skip = i + 1
                cleaning_steps.append(f"üóëÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ #{i+1}")
        
        if rows_to_skip > 0:
            df = df.iloc[rows_to_skip:].reset_index(drop=True)
            cleaning_steps.append(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {rows_to_skip} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –Ω–∞—á–∞–ª–µ")
        
        # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ - –º–æ–∂–µ—Ç —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏?
        if len(df) > 1:
            first_row = df.iloc[0]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–∞ –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            string_count = sum(1 for val in first_row if isinstance(val, str) and len(str(val).strip()) > 0)
            
            # –ï—Å–ª–∏ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ - Unnamed –∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç
            unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
            
            if unnamed_count > len(df.columns) * 0.5 and string_count > len(first_row) * 0.3:
                # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                new_columns = [str(val).strip() if pd.notna(val) else f'Column_{i}' 
                              for i, val in enumerate(first_row)]
                df.columns = new_columns
                df = df.iloc[1:].reset_index(drop=True)
                cleaning_steps.append("üéØ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏")
        
        # –®–ê–ì 3: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        empty_cols = [col for col in df.columns 
                     if df[col].isna().all() or (df[col].astype(str).str.strip() == '').all()]
        if empty_cols:
            df = df.drop(columns=empty_cols)
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(empty_cols)} –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
        
        # –®–ê–ì 4: –£–¥–∞–ª—è–µ–º Unnamed –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –ø—É—Å—Ç—ã–µ –∏–ª–∏ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
        unnamed_to_drop = []
        for col in df.columns:
            if 'Unnamed' in str(col):
                col_values = df[col].dropna()
                # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞ (–≤–æ–∑–º–æ–∂–Ω–æ –∏–Ω–¥–µ–∫—Å—ã)
                if len(col_values) == 0:
                    unnamed_to_drop.append(col)
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–∞ (–∏–Ω–¥–µ–∫—Å—ã)?
                    try:
                        numeric_values = pd.to_numeric(col_values, errors='coerce')
                        if numeric_values.notna().all():
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                            if (numeric_values.diff().dropna() == 1).all():
                                unnamed_to_drop.append(col)
                    except:
                        pass
        
        if unnamed_to_drop:
            df = df.drop(columns=unnamed_to_drop)
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(unnamed_to_drop)} —Å–ª—É–∂–µ–±–Ω—ã—Ö Unnamed –∫–æ–ª–æ–Ω–æ–∫")
        
        # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        rows_before = len(df)
        df = df.dropna(how='all')
        rows_removed = rows_before - len(df)
        if rows_removed > 0:
            cleaning_steps.append(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {rows_removed} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")
        
        # –®–ê–ì 6: –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        df.columns = [str(col).strip() for col in df.columns]
        
        # –®–ê–ì 7: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        for col in df.columns:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–∞
            try:
                numeric_col = pd.to_numeric(df[col], errors='coerce')
                if numeric_col.notna().sum() > len(df) * 0.5:  # –ë–æ–ª–µ–µ 50% —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ
                    df[col] = numeric_col
            except:
                pass
            
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—ã
            if df[col].dtype == 'object':
                try:
                    date_col = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)
                    if date_col.notna().sum() > len(df) * 0.5:
                        df[col] = date_col
                        cleaning_steps.append(f"üìÖ –ö–æ–ª–æ–Ω–∫–∞ '{col}' –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –¥–∞—Ç—ã")
                except:
                    pass
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π DataFrame
        df = df.reset_index(drop=True)
        self.current_df = df
        self.data_metadata["was_edited"] = True
        
        final_shape = df.shape
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        summary = f"""## üßπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- **–§–∞–π–ª:** {self.current_filename}
- **–†–∞–∑–º–µ—Ä:** {original_shape[0]} —Å—Ç—Ä–æ–∫ √ó {original_shape[1]} –∫–æ–ª–æ–Ω–æ–∫

### ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —à–∞–≥–∏ –æ—á–∏—Å—Ç–∫–∏
"""
        for step in cleaning_steps:
            summary += f"- {step}\n"
        
        if not cleaning_steps:
            summary += "- –î–∞–Ω–Ω—ã–µ —É–∂–µ —á–∏—Å—Ç—ã–µ, –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è\n"
        
        summary += f"""
### üìà –†–µ–∑—É–ª—å—Ç–∞—Ç
- **–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:** {final_shape[0]} —Å—Ç—Ä–æ–∫ √ó {final_shape[1]} –∫–æ–ª–æ–Ω–æ–∫
- **–ö–æ–ª–æ–Ω–∫–∏:** {', '.join(df.columns.tolist())}

### üìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""
        # –î–æ–±–∞–≤–ª—è–µ–º preview —Ç–∞–±–ª–∏—Ü—ã
        preview_df = df.head(5)
        summary += self._df_to_markdown(preview_df)
        
        summary += """

–¢–∞–±–ª–∏—Ü–∞ –æ—á–∏—â–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∞–Ω–∞–ª–∏–∑—É! 
–í—ã –º–æ–∂–µ—Ç–µ:
- –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ –¥–∞–Ω–Ω—ã—Ö
- –ü–æ–ø—Ä–æ—Å–∏—Ç—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫
- –ó–∞–ø—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
- –ü–æ–ø—Ä–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–¥–æ–±–∞–≤–∏—Ç—å/—É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Å—Ç–æ–ª–±—Ü—ã)
"""
        
        return {
            "success": True,
            "query": "[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞]",
            "code_attempts": [],
            "final_code": "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
            "result_data": None,
            "text_output": summary,
            "plots": [],
            "error": None,
            "attempts_count": 1,
            "timestamp": datetime.utcnow().isoformat(),
            "load_info": self.data_metadata,
            "modified_csv": self.df_to_csv_base64(df),
            "was_modified": True,
            "cleaning_steps": cleaning_steps
        }
    
    def _df_to_markdown(self, df: pd.DataFrame, max_rows: int = 10) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DataFrame –≤ Markdown —Ç–∞–±–ª–∏—Ü—É
        """
        if df is None or len(df) == 0:
            return "*(–ø—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞)*"
        
        display_df = df.head(max_rows)
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        headers = list(display_df.columns)
        md = "| " + " | ".join(str(h) for h in headers) + " |\n"
        md += "|" + "|".join(["---"] * len(headers)) + "|\n"
        
        # –°—Ç—Ä–æ–∫–∏
        for _, row in display_df.iterrows():
            values = []
            for val in row:
                if pd.isna(val):
                    values.append("")
                elif isinstance(val, float):
                    values.append(f"{val:,.2f}")
                else:
                    values.append(str(val))
            md += "| " + " | ".join(values) + " |\n"
        
        if len(df) > max_rows:
            md += f"\n*...–∏ –µ—â—ë {len(df) - max_rows} —Å—Ç—Ä–æ–∫*\n"
        
        return md

    def generate_code_with_retry(self, user_query: str, schema: Dict,
                                 chat_history: List[Dict] = None,
                                 previous_error: Optional[str] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Python –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é AI (Julius.ai style - –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            schema: –°—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö CSV
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            previous_error: –ü—Ä–µ–¥—ã–¥—É—â–∞—è –æ—à–∏–±–∫–∞ (–¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏)

        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Python –∫–æ–¥
        """
        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç–∞–±–ª–∏—Ü, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –∫–∞–∫ Julius.ai.

üéØ –¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ü–∏—Å–∞—Ç—å –∫–æ–¥ –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –ü–û–≠–¢–ê–ü–ù–û, –õ–û–ì–ò–†–£–ï–¢ –∫–∞–∂–¥—ã–π —à–∞–≥ –∏ –º–æ–∂–µ—Ç –†–ï–î–ê–ö–¢–ò–†–û–í–ê–¢–¨ –¥–∞–Ω–Ω—ã–µ.

üìã –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ö–û–î–ê:

```python
# === –®–ê–ì 1: –ü–û–ù–ò–ú–ê–ù–ò–ï –î–ê–ù–ù–´–• ===
print("üîç –®–ê–ì 1: –ò–∑—É—á–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö...")
print(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

# === –®–ê–ì 2: –ü–†–û–í–ï–†–ö–ê –ò –û–ß–ò–°–¢–ö–ê ===
print("\\nüßπ –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è—é –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö...")

# –ò—â–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≥–∏–±–∫–∏–π –ø–æ–∏—Å–∫)
def find_column(df, keywords):
    for col in df.columns:
        col_lower = str(col).lower()
        if any(keyword.lower() in col_lower for keyword in keywords):
            return col
    return None

# === –®–ê–ì 3: –†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–• (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ===
# –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏–∑–º–µ–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ:

# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ –ø–æ —É—Å–ª–æ–≤–∏—é:
# df = df[df['column'] != 'value']  # –£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ column = value
# df = df.drop(index=[0, 1, 2])  # –£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º

# –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫:
# df = df.drop(columns=['column_name'])

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏:
# df['new_column'] = df['col1'] + df['col2']

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏:
# new_row = {'col1': val1, 'col2': val2}
# df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

# –ó–∞–º–µ–Ω–∞ –∑–Ω–∞—á–µ–Ω–∏–π:
# df['column'] = df['column'].replace('old', 'new')

# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫:
# df = df.rename(columns={'old_name': 'new_name'})

# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞:
# df = df.sort_values(by='column', ascending=True)

# –í–ê–ñ–ù–û! –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö:
# modified_df = df.copy()  # –≠—Ç–æ –≤–µ—Ä–Ω—ë—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é

# === –®–ê–ì 4: –ê–ù–ê–õ–ò–ó / –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ===
print("\\nüìä –®–ê–ì 4: –í—ã–ø–æ–ª–Ω—è—é –∞–Ω–∞–ª–∏–∑...")

# === –®–ê–ì 5: –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===
print("\\n‚úÖ –®–ê–ì 5: –§–æ—Ä–º–∏—Ä—É—é —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç...")

# –°–æ–∑–¥–∞–µ–º MARKDOWN —Ç–∞–±–ª–∏—Ü—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
# –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π print(result) - –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏—Å–≤–æ–π —Å—Ç—Ä–æ–∫—É –≤ result

result = f\"\"\"
## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–û–ø–∏—Å–∞–Ω–∏–µ —á—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ...

| –ö–æ–ª–æ–Ω–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| –î–∞–Ω–Ω—ã–µ  | {value}  |

‚úÖ –ì–æ—Ç–æ–≤–æ!
\"\"\"

# –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã, –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É—Å—Ç–∞–Ω–æ–≤–∏ modified_df:
# modified_df = df.copy()
```

üîß –†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•:

–ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç:
- "—É–¥–∞–ª–∏ —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ..." ‚Üí df = df[~condition] –∏–ª–∏ df.drop()
- "—É–¥–∞–ª–∏ –∫–æ–ª–æ–Ω–∫—É..." ‚Üí df = df.drop(columns=[...])
- "–¥–æ–±–∞–≤—å –∫–æ–ª–æ–Ω–∫—É..." ‚Üí df['new'] = ...
- "–¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫—É..." ‚Üí pd.concat()
- "–∑–∞–º–µ–Ω–∏..." ‚Üí df.replace() –∏–ª–∏ df.loc[]
- "–ø–µ—Ä–µ–∏–º–µ–Ω—É–π..." ‚Üí df.rename()
- "–æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–π..." ‚Üí df.sort_values()
- "–æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ..." ‚Üí df = df[condition]
- "–ø—Ä–∏–≤–µ–¥–∏ –≤ –ø–æ—Ä—è–¥–æ–∫..." ‚Üí –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞

**–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û** –ø–æ—Å–ª–µ –ª—é–±–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–∏:
```python
modified_df = df.copy()
```
–≠—Ç–æ –≤–µ—Ä–Ω—ë—Ç –∏–∑–º–µ–Ω—ë–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é!

üéØ –ö–õ–Æ–ß–ï–í–´–ï –ü–†–ê–í–ò–õ–ê:

1. **–õ–û–ì–ò–†–£–ô –ö–ê–ñ–î–´–ô –®–ê–ì** —á–µ—Ä–µ–∑ print()

2. **–ò–©–ò –ö–û–õ–û–ù–ö–ò –ì–ò–ë–ö–û** - –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º

3. **–§–û–†–ú–ê–¢–ò–†–£–ô –ß–ò–°–õ–ê**:
   - –í —Ç–∞–±–ª–∏—Ü–∞—Ö: `{value:,.0f}` –∏–ª–∏ `{value:,.2f}`
   - –ù–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö: `plt.FuncFormatter(lambda x, p: f'{x:,.0f}')`

4. **–°–û–ó–î–ê–í–ê–ô MARKDOWN –¢–ê–ë–õ–ò–¶–´** (–ù–ï –∫–æ–¥-–±–ª–æ–∫–∏!):
   - –§–æ—Ä–º–∞—Ç: `| –ö–æ–ª–æ–Ω–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |`
   - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: `|---------|----------|`

5. **result = MARKDOWN —Å—Ç—Ä–æ–∫–∞**:
   - –ó–∞–≥–æ–ª–æ–≤–∫–∏ ##, ###
   - –¢–∞–±–ª–∏—Ü—ã –≤ Markdown —Ñ–æ—Ä–º–∞—Ç–µ
   - –≠–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
   - **–ù–ï –ø–µ—á–∞—Ç–∞–π result!**
   - **–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π ``` –≤–æ–∫—Ä—É–≥ —Ç–∞–±–ª–∏—Ü!**

6. **modified_df = df.copy()** - –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª –¥–∞–Ω–Ω—ã–µ!

7. **–û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö** - –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ–±—ä—è—Å–Ω–∏ –∏ –ø–æ–∫–∞–∂–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        column_details = []
        for col in schema['columns']:
            dtype = schema['dtypes'][col]
            missing = schema['missing_values'].get(col, 0)

            examples = []
            if len(schema['sample_data']) > 0:
                for row in schema['sample_data'][:3]:
                    val = row.get(col)
                    if pd.notna(val):
                        examples.append(str(val))

            examples_str = ", ".join(examples[:3]) if examples else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

            col_info = f"  ‚Ä¢ '{col}' ({dtype})"
            if missing > 0:
                col_info += f" [‚ö†Ô∏è –ø—É—Å—Ç—ã—Ö: {missing}]"
            col_info += f"\n    –ü—Ä–∏–º–µ—Ä—ã: {examples_str}"
            column_details.append(col_info)

        user_message = f"""
üìä –î–ê–ù–ù–´–ï CSV –§–ê–ô–õ–ê:

–†–ê–ó–ú–ï–†: {schema['shape']['rows']} —Å—Ç—Ä–æ–∫ √ó {schema['shape']['columns']} –∫–æ–ª–æ–Ω–æ–∫

–ö–û–õ–û–ù–ö–ò:
{chr(10).join(column_details)}

–ü–†–ò–ú–ï–†–´ –ü–ï–†–í–´–• –°–¢–†–û–ö:
{json.dumps(schema['sample_data'][:3], indent=2, ensure_ascii=False)}

üéØ –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_query}

‚ö° –í–ê–ñ–ù–û:
- –õ–æ–≥–∏—Ä—É–π –∫–∞–∂–¥—ã–π —à–∞–≥ —á–µ—Ä–µ–∑ print()
- –ò—â–∏ –∫–æ–ª–æ–Ω–∫–∏ –≥–∏–±–∫–æ (–ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)
- –ü—Ä–æ–≤–µ—Ä—è–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
- –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –í–°–ï —á–∏—Å–ª–∞
- –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Å–∏–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã
- –ï—Å–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—à—å –¥–∞–Ω–Ω—ã–µ - —É—Å—Ç–∞–Ω–æ–≤–∏ modified_df = df.copy()
"""

        if self.data_metadata.get("first_row_is_header"):
            user_message += "\n\n‚úÖ –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ CSV –±—ã–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∏."

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if chat_history and len(chat_history) > 0:
            history_text = "\n\n–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
            for i, item in enumerate(chat_history[-5:], 1):
                history_text += f"\n{i}. –ó–∞–ø—Ä–æ—Å: {item.get('query', '')}\n"
                if item.get('success'):
                    history_text += f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {item.get('text_output', '')[:200]}\n"
            user_message += history_text

        if previous_error:
            user_message += f"""

–ü–†–ï–î–´–î–£–©–ê–Ø –ü–û–ü–´–¢–ö–ê –ó–ê–í–ï–†–®–ò–õ–ê–°–¨ –û–®–ò–ë–ö–û–ô:
{previous_error}

–ò—Å–ø—Ä–∞–≤—å –∫–æ–¥, —É—á–∏—Ç—ã–≤–∞—è —ç—Ç—É –æ—à–∏–±–∫—É.
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.2,
                max_tokens=4000
            )

            code = response.choices[0].message.content.strip()

            # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if code.startswith("```python"):
                code = code[9:]
            if code.startswith("```"):
                code = code[3:]
            if code.endswith("```"):
                code = code[:-3]

            return code.strip()

        except Exception as e:
            error_msg = str(e)

            if "401" in error_msg or "Unauthorized" in error_msg or "User not found" in error_msg:
                raise Exception(
                    f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenRouter (401): API –∫–ª—é—á –Ω–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –∏—Å—Ç–µ–∫. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENROUTER_API_KEY –≤ .env —Ñ–∞–π–ª–µ. "
                    f"–ü–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π –∫–ª—é—á –Ω–∞ https://openrouter.ai/keys. "
                    f"–î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "403" in error_msg:
                raise Exception(
                    f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): –£ API –∫–ª—é—á–∞ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏ {self.model} "
                    f"–∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            elif "429" in error_msg:
                raise Exception(
                    f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429): –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. "
                    f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞. –î–µ—Ç–∞–ª–∏: {error_msg}"
                )
            else:
                raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {error_msg}")

    def analyze(self, user_query: str = None, chat_history: List[Dict] = None) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è API
        –ï—Å–ª–∏ user_query –ø—É—Å—Ç–æ–π - –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –ø—É—Å—Ç–æ–π - –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞)
            chat_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ API
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω",
                "timestamp": datetime.utcnow().isoformat()
            }

        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
        if not user_query or user_query.strip() == "":
            return self.auto_clean_data()

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö
        schema = self.analyze_csv_schema(self.current_df)

        result = {
            "success": False,
            "query": user_query,
            "code_attempts": [],
            "final_code": None,
            "result_data": None,
            "text_output": None,
            "plots": [],
            "error": None,
            "attempts_count": 0,
            "timestamp": datetime.utcnow().isoformat(),
            "load_info": self.data_metadata,
            "modified_csv": None,
            "was_modified": False
        }

        previous_error = None

        for attempt in range(self.max_retries):
            result["attempts_count"] = attempt + 1

            try:
                code = self.generate_code_with_retry(
                    user_query,
                    schema,
                    chat_history,
                    previous_error
                )

                result["code_attempts"].append({
                    "attempt": attempt + 1,
                    "code": code,
                    "success": False
                })

            except Exception as e:
                result["error"] = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {str(e)}"
                break

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
            success, exec_result, output, plot_base64_list, modified_df = self.execute_python_code(
                code, self.current_df
            )

            if success:
                result["success"] = True
                result["final_code"] = code
                result["result_data"] = exec_result
                result["text_output"] = output
                result["plots"] = plot_base64_list
                result["code_attempts"][-1]["success"] = True
                
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã
                if modified_df is not None:
                    self.current_df = modified_df
                    self.data_metadata["was_edited"] = True
                    result["modified_csv"] = self.df_to_csv_base64(modified_df)
                    result["was_modified"] = True
                
                break
            else:
                previous_error = output
                result["code_attempts"][-1]["error"] = output

                if attempt == self.max_retries - 1:
                    result["error"] = f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫"
                    result["error_details"] = output

        return result

    def get_schema_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º CSV —Ñ–∞–π–ª–µ

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ö–µ–º–µ –¥–∞–Ω–Ω—ã—Ö
        """
        if self.current_df is None:
            return {
                "success": False,
                "error": "CSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
            }

        schema = self.analyze_csv_schema(self.current_df)
        return {
            "success": True,
            "schema": schema,
            "timestamp": datetime.utcnow().isoformat()
        }

    def get_current_csv(self) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π CSV –≤ base64

        Returns:
            Base64 —Å—Ç—Ä–æ–∫–∞ CSV –∏–ª–∏ None
        """
        return self.df_to_csv_base64()

    def cleanup(self):
        """
        –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
        """
        if self.current_df is not None:
            del self.current_df
            self.current_df = None

        if self.original_df is not None:
            del self.original_df
            self.original_df = None

        plt.close('all')
        gc.collect()
